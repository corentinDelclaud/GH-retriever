Namespace(model_name='graph_llm', project='project_g_retriever', seed=0, dataset='expla_graphs', lr=1e-05, wd=0.05, patience=2, batch_size=8, grad_steps=2, num_epochs=10, warmup_epochs=1, eval_batch_size=16, llm_model_name='7b', llm_model_path='', llm_frozen='True', llm_num_virtual_tokens=10, output_dir='output', max_txt_len=512, max_new_tokens=32, max_memory=[40], gnn_model_name='gt2', gnn_num_layers=4, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_num_heads=4, gnn_dropout=0.0)
Loading LLAMA
Loading checkpoint shards: 100%|█████████████| 2/2 [00:01<00:00,  1.51it/s]
Freezing LLAMA!
Finish loading LLAMA!
trainable params: 90236928 || all params: 6828652544 || trainable%: 1.3214455914774392
 60%|████████████████████▍             | 1242/2070 [16:13<09:35,  1.44it/s]/home/naeem/miniconda3/envs/g_retriever_HYBRID/lib/python3.9/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
Epoch: 0|10: Train Loss (Epoch Mean): 0.9053116969872212
Epoch: 0|10: Val Loss: 0.3593897919569697
Saving checkpoint at epoch 0 to output/expla_graphs/model_name_graph_llm_llm_model_name_7b_llm_frozen_True_max_txt_len_512_max_new_tokens_32_gnn_model_name_gt2_patience_2_num_epochs_10_seed0_checkpoint_best.pth.
Epoch 0 Val Loss 0.3593897919569697 Best Val Loss 0.3593897919569697 Best Epoch 0
Epoch: 1|10: Train Loss (Epoch Mean): 0.26236088813512004
Epoch: 1|10: Val Loss: 0.1805449301776077
Saving checkpoint at epoch 1 to output/expla_graphs/model_name_graph_llm_llm_model_name_7b_llm_frozen_True_max_txt_len_512_max_new_tokens_32_gnn_model_name_gt2_patience_2_num_epochs_10_seed0_checkpoint_best.pth.
Epoch 1 Val Loss 0.1805449301776077 Best Val Loss 0.1805449301776077 Best Epoch 1
Epoch: 2|10: Train Loss (Epoch Mean): 0.2046969019362917
Epoch: 2|10: Val Loss: 0.27281938360164143
Epoch 2 Val Loss 0.27281938360164143 Best Val Loss 0.1805449301776077 Best Epoch 1
Epoch: 3|10: Train Loss (Epoch Mean): 0.19149455718818192
Epoch: 3|10: Val Loss: 0.16252341910232124
Saving checkpoint at epoch 3 to output/expla_graphs/model_name_graph_llm_llm_model_name_7b_llm_frozen_True_max_txt_len_512_max_new_tokens_32_gnn_model_name_gt2_patience_2_num_epochs_10_seed0_checkpoint_best.pth.
Epoch 3 Val Loss 0.16252341910232124 Best Val Loss 0.16252341910232124 Best Epoch 3
Epoch: 4|10: Train Loss (Epoch Mean): 0.1148553232134372
Epoch: 4|10: Val Loss: 0.2603415494616326
Epoch 4 Val Loss 0.2603415494616326 Best Val Loss 0.16252341910232124 Best Epoch 3
Epoch: 5|10: Train Loss (Epoch Mean): 0.08130773688127953
Epoch: 5|10: Val Loss: 0.38317211191186806
Epoch 5 Val Loss 0.38317211191186806 Best Val Loss 0.16252341910232124 Best Epoch 3
Early stop at epoch 5
  warnings.warn(
path: output/expla_graphs/model_name_graph_llm_llm_model_name_7b_llm_frozen_True_max_txt_len_512_max_new_tokens_32_gnn_model_name_gt2_patience_2_num_epochs_10_seed0.csv
Loading checkpoint from output/expla_graphs/model_name_graph_llm_llm_model_name_7b_llm_frozen_True_max_txt_len_512_max_new_tokens_32_gnn_model_name_gt2_patience_2_num_epochs_10_seed0_checkpoint_best.pth.
 60%|████████████████████▍             | 1242/2070 [17:00<11:20,  1.22it/s]
100%|██████████████████████████████████████| 35/35 [00:24<00:00,  1.44it/s]
Test Acc 0.9061371841155235
/home/naeem/miniconda3/envs/g_retriever_HYBRID/lib/python3.9/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
