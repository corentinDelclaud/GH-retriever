{
  "os": "Linux-6.8.0-60-generic-x86_64-with-glibc2.35",
  "python": "CPython 3.9.23",
  "startedAt": "2025-06-07T00:44:17.544107Z",
  "args": [
    "--dataset",
    "scene_graphs",
    "--model_name",
    "inference_llm",
    "--llm_model_name",
    "7b_chat",
    "--seed",
    "1"
  ],
  "program": "/home/naeem/Documents/corentin/git/Internship4rd/2/G-retriever Model/Efficient-G-Retriever-main Hybrid/inference.py",
  "codePath": "2/G-retriever Model/Efficient-G-Retriever-main Hybrid/inference.py",
  "git": {
    "remote": "https://github.com/corentinDelclaud/Internship4rd.git",
    "commit": "4ca3d513a9f88a78254df6b74e55db902172d1da"
  },
  "email": "corentin.delclaud@etu.umontpellier.fr",
  "root": "/home/naeem/Documents/corentin/git/Internship4rd/2/G-retriever Model/Efficient-G-Retriever-main Hybrid",
  "host": "sdu-133749",
  "executable": "/home/naeem/miniconda3/envs/g_retriever_HYBRID/bin/python",
  "codePathLocal": "inference.py",
  "cpu_count": 16,
  "cpu_count_logical": 24,
  "gpu": "NVIDIA RTX A6000",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "979019075584",
      "used": "592596611072"
    }
  },
  "memory": {
    "total": "134838816768"
  },
  "cpu": {
    "count": 16,
    "countLogical": 24
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA RTX A6000",
      "memoryTotal": "51527024640",
      "cudaCores": 10752,
      "architecture": "Ampere",
      "uuid": "GPU-0b94dfef-1e0f-fa69-b010-99ca1fd8ad6f"
    }
  ],
  "cudaVersion": "12.2"
}